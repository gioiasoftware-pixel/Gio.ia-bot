# Feature: Messaggi Audio (Speech-to-Text)

## ğŸ“‹ Stato
**Status**: Planned (da implementare in seguito)  
**PrioritÃ **: Media  
**Stima**: 2-3 ore di sviluppo

## ğŸ¯ Obiettivo
Permettere agli utenti di inviare messaggi vocali (voice notes, audio files) che vengono automaticamente trascritti e processati come messaggi testuali.

## ğŸ”§ Implementazione Tecnica

### Componenti da Aggiungere

1. **Nuovi Handler Bot** (`src/bot.py`)
   - `MessageHandler(filters.VOICE, handle_voice)`
   - `MessageHandler(filters.AUDIO, handle_audio)`
   - `MessageHandler(filters.VIDEO_NOTE, handle_video_note)` (opzionale)

2. **Trascrittore Audio** (`src/audio_transcriber.py` - nuovo file)
   - Metodo: OpenAI Whisper API (prima scelta)
   - Fallback: whisper.cpp locale o Vosk
   - Conversione ffmpeg se necessario (OGG/Opus â†’ WAV 16k mono)
   - Gestione timeout e chunking per audio lunghi

3. **Utility Conversione** (`src/audio_utils.py` - nuovo file, opzionale)
   - Wrapper ffmpeg per normalizzare formati
   - Validazione dimensione/durata

### Flusso Operativo

```
1. Utente invia audio â†’ Bot riceve file_id
2. Download file via Bot API â†’ bytes
3. Conversione formati (se necessario) â†’ WAV/MP3
4. Invio a Whisper API â†’ trascrizione testo
5. Salvataggio trascrizione in LOG interazione (role='user')
6. Processamento come messaggio testo normale â†’ get_ai_response()
7. Risposta all'utente + salvataggio in LOG (role='assistant')
```

### Features UX

- Messaggio intermedio: "ğŸ™ï¸ Ricevuto audio, trascrivo..."
- Bottone "âœï¸ Modifica testo" se confidence bassa
- Cache trascrizioni per `file_id` (evita re-trascrizione su retry)
- Rate limiting audio (es. 3 audio/minuto per utente)
- Comando `/audio off` per disabilitare feature per utente

### Configurazione ENV

```env
AUDIO_TRANSCRIBER=whisper_api|whisper_local|vosk
OPENAI_API_KEY=<giÃ  presente>
AUDIO_MAX_SECONDS=120
AUDIO_MAX_SIZE_MB=25
FFMPEG_PATH=/usr/bin/ffmpeg  # Se conversione locale
```

### Dipendenze Nuove

```txt
openai>=2.0.0  # GiÃ  presente per Whisper API
ffmpeg-python>=0.2.0  # Opzionale, solo se conversione locale
```

### Note Implementazione

- âœ… Tutto asincrono (giÃ  architettura bot)
- âœ… Riutilizzo LOG interazione esistente
- âœ… Nessuna nuova tabella DB necessaria
- âœ… Trascrizione â†’ testo â†’ pipeline esistente AI
- âš ï¸ Costi Whisper API: ~â‚¬0.006 per minuto (valutare limiti)
- âš ï¸ CPU: se uso whisper locale, valutare worker separato

## ğŸ“ TODO Implementazione

- [ ] Creare `src/audio_transcriber.py` con wrapper Whisper API
- [ ] Aggiungere handler VOICE/AUDIO in `src/bot.py`
- [ ] Integrare trascrizione nel flusso chat_handler esistente
- [ ] Aggiungere cache trascrizioni (tabella o Redis opzionale)
- [ ] Template messaggi feedback utente ("ğŸ™ï¸ Trascrivo...")
- [ ] Rate limiter specifico per audio
- [ ] Comando `/audio off/on` per toggle feature
- [ ] Testing con vari formati audio (OGG, MP3, WAV)
- [ ] Documentazione feature per utenti finali

## ğŸ”— Riferimenti

- [Telegram Bot API - Voice Messages](https://core.telegram.org/bots/api#voice)
- [OpenAI Whisper API](https://platform.openai.com/docs/guides/speech-to-text)
- [Python Telegram Bot - Filters](https://python-telegram-bot.readthedocs.io/en/stable/telegram.ext.filters.html)


